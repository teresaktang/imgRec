{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of AICode.ipynb","provenance":[{"file_id":"1ade5p9e6lTTJsuJNlvwVAMWssjM6FIgm","timestamp":1638656144084}],"collapsed_sections":[],"authorship_tag":"ABX9TyOYpSo+Coh9O0JtVo+nSrQz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H6UJo62OHJg1"},"source":["Topic: Image recognition"]},{"cell_type":"code","metadata":{"id":"tlG5YZCuhzld","executionInfo":{"status":"ok","timestamp":1638655434184,"user_tz":0,"elapsed":550,"user":{"displayName":"Teresa Tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16883424348819496266"}}},"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.applications.vgg16 import decode_predictions\n","import os\n","import tensorflow as tf\n","import numpy as np"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-elym9_-Xdi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638655437737,"user_tz":0,"elapsed":1676,"user":{"displayName":"Teresa Tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16883424348819496266"}},"outputId":"0220e32e-7acb-4229-c61f-1a63b0f59cd8"},"source":["tf.keras.applications.VGG16(\n","    include_top=True,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.engine.functional.Functional at 0x7f11f662e910>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFdVEC2wh0hv","executionInfo":{"status":"ok","timestamp":1638655674792,"user_tz":0,"elapsed":2427,"user":{"displayName":"Teresa Tang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16883424348819496266"}},"outputId":"4b279a31-d571-4745-be0e-7b1c70243d28"},"source":["model = VGG16()\n","plot_model(model, to_file='vgg_model.png')\n","model.summary()\n","\n","imageList = []\n","tImage = []\n","\n","filePath = [i for i in (os.path.join('/content/sample_animal', f) for f in os.listdir('/content/sample_animal')) if os.path.isfile(i)]\n","for n in filePath:\n","  #load_img() function to load the image and resize it to 224 x 224 pixels.\n","  img = image.load_img(n, target_size = (224, 224))\n","  #The img_to_array() function adds channels: (224, 224, 3) for RGB #and (224, 224, 1) for gray image.\n","  transformedImage = image.img_to_array(img)\n","  print(transformedImage.shape)\n","  transformedImage = np.expand_dims(transformedImage, axis = 0)\n","  print(transformedImage.shape)\n","  transformedImage = preprocess_input(transformedImage)\n","  tImage.append(transformedImage)\n","  #predict() function classify input image in 1000 possible classes.\n","  prediction = model.predict(transformedImage)\n","  #print(prediction)\n","  print(prediction.shape)\n","  predictionLabel = decode_predictions(prediction, top = 5)\n","  print(predictionLabel)\n","  print('%s (%.2f%%)' % (predictionLabel[0][0][1], predictionLabel[0][0][2]*100 ))\n","\n"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_19 (InputLayer)       [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n","(224, 224, 3)\n","(1, 224, 224, 3)\n","(1, 1000)\n","[[('n02509815', 'lesser_panda', 1.0), ('n02443114', 'polecat', 4.748144e-09), ('n02441942', 'weasel', 7.264812e-10), ('n02510455', 'giant_panda', 3.102495e-10), ('n02493509', 'titi', 1.6836826e-10)]]\n","lesser_panda (100.00%)\n","(224, 224, 3)\n","(1, 224, 224, 3)\n","(1, 1000)\n","[[('n02105162', 'malinois', 0.4597809), ('n02106662', 'German_shepherd', 0.11956334), ('n02105412', 'kelpie', 0.11075966), ('n02115641', 'dingo', 0.09321571), ('n02091244', 'Ibizan_hound', 0.03756441)]]\n","malinois (45.98%)\n","(224, 224, 3)\n","(1, 224, 224, 3)\n","(1, 1000)\n","[[('n01675722', 'banded_gecko', 0.7470846), ('n01687978', 'agama', 0.088694505), ('n01644900', 'tailed_frog', 0.045506008), ('n01685808', 'whiptail', 0.029638898), ('n01694178', 'African_chameleon', 0.022551935)]]\n","banded_gecko (74.71%)\n","(224, 224, 3)\n","(1, 224, 224, 3)\n","(1, 1000)\n","[[('n02124075', 'Egyptian_cat', 0.75156814), ('n02123045', 'tabby', 0.12183662), ('n02123159', 'tiger_cat', 0.054483928), ('n02127052', 'lynx', 0.04093091), ('n06785654', 'crossword_puzzle', 0.0021389264)]]\n","Egyptian_cat (75.16%)\n"]}]},{"cell_type":"code","metadata":{"id":"UCrO_rYdfT69"},"source":[""],"execution_count":null,"outputs":[]}]}